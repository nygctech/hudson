{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "import anndata\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask\n",
    "from pyseq import image_analysis as ia\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from dask.distributed import Client\n",
    "import numba\n",
    "from os import makedirs, getcwd\n",
    "import joblib\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import skimage\n",
    "import time\n",
    "from os.path import exists, join\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import parallel_backend\n",
    "from dask.distributed import progress\n",
    "#%run /gpfs/commons/home/jsingh/util_pyseq.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageAnalysis::Opened m387ntga2 \n"
     ]
    }
   ],
   "source": [
    "#Loading Data\n",
    "im = ia.get_HiSeqImages(image_path = '/gpfs/commons/home/jsingh/zarrs/m387ntga2.zarr')\n",
    "labels = skimage.io.imread('/gpfs/commons/groups/nygcfaculty/PySeq/20210428_mouse_genotype_2/segmented_sections/m387ntga2_labels.tiff')\n",
    "labels = dask.array.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format = one_z_plane_obj_step_channel_cycle\n",
    "array_object_list = []\n",
    "name_object_list = []\n",
    "for i in im.im['channel'].values:\n",
    "    for j in im.im['cycle'].values:\n",
    "        #for k #in im.im['obj_step'].values[1]:\n",
    "            k = 8028\n",
    "            name = \"one_x_plane_\"+str(i)+\"_\"+str(j)+\"_\"+str(k)\n",
    "            name_object_list.append(name)\n",
    "            nme = im.im.sel(obj_step = k, cycle=j, channel = i)\n",
    "            array_object_list.append(nme)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ INITIATING CLUSTER ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster(queue_name = 'pe2', log_dir=None):\n",
    "    \"\"\" Make dask cluster w/ workers = 2 cores, 32 G mem, and 1 hr wall time.\n",
    "\n",
    "        return cluster, client\n",
    "    \"\"\"\n",
    "    if log_dir is None:\n",
    "        log_dir = join(getcwd(),'dask_logs')\n",
    "        makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    cluster = SLURMCluster(\n",
    "                queue = queue_name, \n",
    "                cores = 12 ,\n",
    "                memory = '128G',\n",
    "                walltime='1:00:00',\n",
    "                log_directory=log_dir)\n",
    "                #extra=[\"--lifetime\", \"55m\", \"--lifetime-stagger\", \"4m\"])\n",
    "    client = Client(cluster, timeout=\"50s\")\n",
    "\n",
    "    return cluster, client\n",
    "\n",
    "cluster, client = get_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://10.4.200.50:46832/status'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale_cluster(count): \n",
    "    cluster.scale(count)\n",
    "    return cluster.dashboard_link\n",
    "scale_cluster(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or specify cores or memory directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane = array_object_list[0] #sample plane "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane.values[labels == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Future' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m progress(futures)\n\u001b[1;32m     10\u001b[0m result_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     12\u001b[0m     result_list[i] \u001b[38;5;241m=\u001b[39m futures[i]\u001b[38;5;241m.\u001b[39mresult()\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Future' has no len()"
     ]
    }
   ],
   "source": [
    "#Way 1: Using Data As Is (No Persit) with Dask Futures\n",
    "plane = array_object_list[0]\n",
    "def get_pixels(lab):\n",
    "    m = plane.values[labels == lab+1].mean()\n",
    "    return m\n",
    "\n",
    "futures = client.submit(get_pixels, range(5))\n",
    "progress(futures)\n",
    "\n",
    "result_list = np.zeros(20)\n",
    "for i in range(len(futures)):\n",
    "    result_list[i] = futures[i].result()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Way 2: Using with Dask Persist with Dask Futures\n",
    "plane_persisted = array_object_list[0].persist()\n",
    "def get_pixels(lab):\n",
    "    m = plane_persisted.values[labels == lab+1].mean()\n",
    "    return m\n",
    "from dask.distributed import progress\n",
    "futures = client.map(get_pixels, range(100))\n",
    "#progress(futures)\n",
    "\n",
    "\n",
    "result_list = np.zeros(100)\n",
    "for i in range(len(futures)):\n",
    "    result_list[i] = futures[i].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Way 3: Computing the same using dask compute without persisting Data\n",
    "def get_pixels(lab):\n",
    "    m = plane.values[labels == lab+1].mean()\n",
    "    return m\n",
    "\n",
    "with parallel_backend('dask',scheduler_host=cluster.scheduler._address):\n",
    "    results = Parallel(n_jobs=-1)(delayed(get_pixels)(lab) for lab in range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Way 4: Computing way 3 with persist\n",
    "def get_pixels(lab):\n",
    "    m = plane_persisted.values[labels == lab+1].mean()\n",
    "    return m\n",
    "\n",
    "with parallel_backend('dask',scheduler_host=cluster.scheduler._address):\n",
    "    results = Parallel(n_jobs=-1)(delayed(get_pixels)(lab) for lab in range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk = dask.array.asarray(plane.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Way 5: Dask Masked Array\n",
    "dk = dask.array.asarray(plane.values)\n",
    "def get_pixels(lab):\n",
    "    m = dask.array.ma.masked_array(dk,np.squeeze([labels == lab]))\n",
    "    mv = dask.array.mean(m)\n",
    "    return mv\n",
    "\n",
    "futures = client.map(get_pixels, range(5))\n",
    "\n",
    "result_list = np.zeros(20)\n",
    "for i in range(len(futures)):\n",
    "    result_list[i] = futures[i].result()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Way 6: Dask Masked Array With Persist \n",
    "dk = dask.array.asarray(persisted_plane.values)\n",
    "def get_pixels(lab):\n",
    "    m = dask.array.ma.masked_array(dk,np.squeeze([labels == lab]))\n",
    "    mv = dask.array.mean(m)\n",
    "    return mv\n",
    "\n",
    "futures = client.map(get_pixels, range(5))\n",
    "\n",
    "result_list = np.zeros(20)\n",
    "for i in range(len(futures)):\n",
    "    result_list[i] = futures[i].result()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Way 5 using joblib \n",
    "def get_pixels(lab):\n",
    "    m = dask.array.ma.masked_array(dk,np.squeeze([labels == lab]))\n",
    "    mv = dask.array.mean(m)\n",
    "    return mv\n",
    "\n",
    "with parallel_backend('dask',scheduler_host=cluster.scheduler._address):\n",
    "    results = Parallel(n_jobs=-1)(delayed(get_pixels)(lab) for lab in range(100))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Way x : Dask image functions\n",
    "import dask_image\n",
    "import dask_image.ndmeasure\n",
    "\n",
    "index = list(range(11000))\n",
    "del index[0]\n",
    "\n",
    "ar = dask_image.ndmeasure.labeled_comprehension(image = plane, \n",
    "                                                label_image = labels, index = index, func = dask_image.ndmeasure.mean,\n",
    "                                                out_dtype = float, default = None, pass_positions = False)\n",
    "v = ar.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 137.62089726,  114.19090909,  115.02439024,  125.22727273,\n",
       "       1151.01442716,  380.        ,  385.        ,  136.9754902 ,\n",
       "        240.        ,  134.63862928,  146.06842338,  137.85227273,\n",
       "        134.875     ,  331.425     ,  136.73469388,  132.19198312,\n",
       "        410.8       ,  350.85861183,  371.57823129,  404.5       ,\n",
       "        336.        ,  437.83830673,  294.06445312,  218.54237288,\n",
       "        323.56      ,  316.2173913 ,  306.51856594,  313.83333333,\n",
       "        310.53061224,  293.20774648,  345.        ,  360.5       ,\n",
       "        307.        ,  555.1       ,  299.07142857,  490.27358491,\n",
       "        343.01433121,  280.18867925,  279.95454545,  317.25294118,\n",
       "        408.75      ,  277.8       ,  341.34324943,  261.75      ,\n",
       "        388.5       ,  410.02564103,  343.25      ,  404.66666667,\n",
       "        321.33692308,  438.42753623,  279.38111888,  480.75      ,\n",
       "        391.2       ,  338.        ,  535.81031866,  385.17741935,\n",
       "        431.5       ,  409.28205128,  395.25      ,  396.44759207,\n",
       "        405.46666667,  434.6       ,  372.21428571,  986.66666667,\n",
       "        364.86393089, 1032.87926136,  344.84507042,  650.8       ,\n",
       "        387.81354916,  457.03278689,  445.10714286,  382.08860759,\n",
       "        458.54545455, 1255.26995305,  460.        ,  328.23170732,\n",
       "        462.03448276,  413.23619048,  337.2       ,  502.31693989,\n",
       "        464.61764706,  402.68659794,  454.76666667, 1648.5       ,\n",
       "        580.33333333,  335.        ,  417.4       ,  612.33333333,\n",
       "        429.32467532, 1001.13736264,  418.19347037,  405.4       ,\n",
       "        533.10857664,  261.44670051,  428.        ,  354.03064699,\n",
       "        409.69164882,  370.31818182,  444.41902516])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADJUSTING TIMEOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distributed==2022.5.2\n",
      "dask==2022.5.2\n",
      "matplotlib==3.5.2\n",
      "zarr==2.10.3\n",
      "numpy==1.21.5\n",
      "scipy==1.8.1\n",
      "progress==1.6\n",
      "joblib==1.1.0\n",
      "numba==0.55.1\n",
      "anndata==0.7.8\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import types\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            # Split ensures you get root package, \n",
    "            # not just imported function\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        # Some packages are weird and have different\n",
    "        # imported names vs. system/pip names. Unfortunately,\n",
    "        # there is no systematic way to get pip names from\n",
    "        # a package's imported name. You'll have to add\n",
    "        # exceptions to this list manually!\n",
    "        poorly_named_packages = {\n",
    "            \"PIL\": \"Pillow\",\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "# The only way I found to get the version of the root package\n",
    "# from only the name of the package is to cross-check the names \n",
    "# of installed packages vs. imported packages\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "spatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
