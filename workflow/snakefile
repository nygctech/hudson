from os.path import join
import configparser
import subprocess
import yaml
from math import log, ceil


exp_dir = config['experiment_directory']
exp_conf_path = config.get('experiment_config')
if exp_conf_path is None:
    exp_conf_path = join(exp_dir, 'logs/config.cfg')
exp_conf = configparser.ConfigParser()
exp_conf.read(exp_conf_path)

experiment_name = exp_conf.get('experiment','experiment name')
method = exp_conf.get('experiment','method')
output_dir = join(config['output_directory'], experiment_name)
sections = exp_conf.options('sections')
sections = [s.replace('_','') for s in sections]

core_limit = cluster_config.get('nodes')


def get_gpu():
    result = subprocess.run(['sinfo -p gpu | grep idle'],shell=True,capture_output=True,text=True)
    gpu_available = 0
    if 'pe2dg2' in result.stdout:
        gpu_available = 1

    return gpu_available  

    
def get_tiles(wildcards):
    try:
        with open(join(output_dir,f'summary_{wildcards.sections}.yaml')) as f:
            section_info = yaml.safe_load(f)  
        tiles = section_info['tiles'] 
    except:
        tiles = 1
    return tiles

def get_cores(section):
    try:
        with open(join(output_dir,f'summary_{section}.yaml')) as f:
            section_info = yaml.safe_load(f)  
        tiles = section_info['tiles']     
    except:
        tiles = 8
    return tiles
    
def get_cycles(wildcards):
    try:
        with open(join(output_dir,f'summary_{wildcards.sections}.yaml')) as f:
            section_info = yaml.safe_load(f)
        cycles = section_info['cycles']
    except:
        cycles = exp_conf.get('experiment', 'cycles')
    return cycles
    
def get_mem(wildcards):
    try:
        with open(join(output_dir,f'summary_{wildcards.sections}.yaml')) as f:
            section_info = yaml.safe_load(f)    
        mb = section_info['planesizeMB']
        mb = ceil(mb/8000)*8000 * get_cores(wildcards)
    except:
        mb = 8000
    return mb



def get_picasso_time(wildcards):
    return get_cycles(wildcards)*60 # minutes
   
  
# rule all:
#     input:
#         expand('{dir}/net_neighborhood/{s}.pkl', dir = output_dir, s = sections)

rule all:
    input:
        expand('{dir}/tables/{s}.csv', dir = output_dir, s = sections)

rule saveraw:
    input:
        {exp_conf_path},
    params:
        section = '{sections}'
    log:
        '{output_dir}/logs/saveraw_{sections}.log', 
        '{output_dir}/logs/saveraw_{sections}.html'
    output:
        directory('{output_dir}/raw_zarr/{sections}.zarr'),
        '{output_dir}/summary_{sections}.yaml',
        '{output_dir}/exp_conf/{sections}.cfg'
    conda:
        'envs/pyseq-image.yaml'
    script:
        'scripts/save_raw.py'   


rule fix_lighting:
    input:
        '{output_dir}/raw_zarr/{sections}.zarr',
    params:
        overlap = exp_conf.get(method,'overlap', fallback = False),
        direction = exp_conf.get(method,'overlap direction', fallback = False)
    log:
        '{output_dir}/logs/fixlighting_{sections}.log',
        '{output_dir}/logs/fixlighting_{sections}.html'
    output:
        directory('{output_dir}/processed_zarr/{sections}.zarr'),
    conda:
        'envs/pyseq-image.yaml'
    script:
        'scripts/preprocess.py'

#if get_gpu():
#    cluster_config.update({'picasso':config['gpu_spec']})


rule picasso:
    input:
        '{output_dir}/processed_zarr/{sections}.zarr',
        '{output_dir}/summary_{sections}.yaml'
    output:
        '{output_dir}/final_zarr/picasso_{sections}.yaml'
    params:
        max_iter = config.get('unmix',{'max_iter':100}).get('max_iter'),
        section = '{sections}'
    log:
        '{output_dir}/logs/picasso_{sections}.log'
    threads: 8
    resources:
        mem_mb = get_mem,
        runtime = get_picasso_time
    conda:
        'envs/unmix.yaml'
    script:
        'scripts/picasso.py'
# Reset nodes to core_limit after specifying cores in rule
cluster_config.update({'nodes':core_limit})


rule unmix:
    input:
        '{output_dir}/processed_zarr/{sections}.zarr',
        '{output_dir}/final_zarr/picasso_{sections}.yaml',
        '{output_dir}/summary_{sections}.yaml'
    params:
        section = '{sections}'
    output:
        directory('{output_dir}/final_zarr/{sections}.zarr')
    log:
        '{output_dir}/logs/unmix_{sections}.log',
        '{output_dir}/logs/unmix_{sections}.html'
    conda:
        'envs/unmix.yaml'
    script:
        'scripts/unmix.py'

if get_gpu():
    cluster_config.update({'segmentation':config['gpu_spec']})
    
rule segmentation:
    input:
        '{output_dir}/final_zarr/{sections}.zarr',
        '{output_dir}/summary_{sections}.yaml'
    params:
        section = '{sections}'
    output:
       '{output_dir}/masks/{sections}.tiff'
    resources:
        mem_mb = get_mem
    log:
        '{output_dir}/logs/segment_{sections}.log',
    conda:
        'envs/segmentation.yaml'
    script:
        'scripts/segmentation.py'


rule feature_extraction:
    input:
        '{output_dir}/final_zarr/{sections}.zarr',
        '{output_dir}/masks/{sections}.tiff'
    params:
        tiles = get_tiles,
        section = '{sections}'
    output:
        '{output_dir}/features/{sections}.h5mu'
    log: 
        '{output_dir}/logs/intensity_{sections}.log'
    threads: 8
    resources:
        mem_mb = get_mem
    conda:
        'envs/features.yaml'
    script:
        'scripts/feature_extraction.py'
# Reset nodes to core_limit after specifying cores in rule
cluster_config.update({'nodes':core_limit})



#rule anndata:
#    input:
#        '{output_dir}/masks/{sections}.tiff',
#        '{output_dir}/intensities/{sections}.pkl'
#        
#    output:
#        '{output_dir}/anndata/{sections}.h5mu'
#    resources:
#        mem_mb = 32000
#    conda:
#        'envs/make_anndata.yaml'
#    script:
#        'scripts/make_anndata.py'



rule celltype:
    input:
        '{output_dir}/features/{sections}.h5mu'
    output:
        '{output_dir}/tables/{sections}.csv'
    log:
        '{output_dir}/logs/cell_type_{sections}.log'
    params:
        ref = config["celltype"]["seurat"],
        typecol = config["celltype"]["typecol"],
        genedict = config["celltype"].get("genedict", {})
    resources:
        mem_mb = 32000
    conda:
        'envs/celltype.yaml'
    shell:
        '''
            Rscript scripts/celltype.R \
              --input_h5={input} \
              --output={output} \
              --ref={params.ref} \
              --typecol={params.typecol} \
              --genedict={params.genedict} > {log}
        '''

# rule spatial_neighborhood:
#     input:
#        '{output_dir}/anndata/{sections}.h5mu',
#        '{output_dir}/tables/{sections}.csv'
#     output:
#        '{output_dir}/cell_neighborhood/{sections}.pkl',
#        '{output_dir}/net_neighborhood/{sections}.pkl'
#     resources:
#         mem_mb = 32000
#     conda:
#         'envs/spatial_neighbor.yaml'
#     script:
#         'scripts/spatial_neighborhood.py'
