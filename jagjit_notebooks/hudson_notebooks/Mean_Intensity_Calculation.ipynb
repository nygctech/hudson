{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/jsingh/.conda/envs/spatial/lib/python3.9/site-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import tmpfile\n"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import dask\n",
    "from pyseq import image_analysis as ia\n",
    "from dask.distributed import Client\n",
    "import torch\n",
    "import joblib\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import skimage\n",
    "import time\n",
    "import pickle\n",
    "from os.path import exists, join\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import parallel_backend\n",
    "from dask.distributed import progress\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class snakemake():\n",
    "    input  = ['/gpfs/commons/home/jsingh/results/20210323_4i4color/final_zarr/m1a.zarr', \n",
    "              '/gpfs/commons/home/jsingh/results/20210323_4i4color/masks/m1a.tiff']\n",
    "    output = ['/gpfs/commons/home/jsingh/results/m1a.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = skimage.io.imread(snakemake.input[1])\n",
    "image_path = Path(snakemake.input[0])\n",
    "im_name = image_path.stem\n",
    "image = xr.open_zarr(image_path).to_array()\n",
    "image = image.squeeze().drop_vars('variable').rename(im_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_list = ['LMN1b', 'GFAP','ELAVL2','MBP','PVALB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_dict = {}\n",
    "for mark in marker_list:\n",
    "    try:\n",
    "        plane_dict.update({mark: image.sel(marker = mark)})\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LMN1b': <xarray.DataArray 'm1a' (row: 1830, col: 2044)>\n",
       " dask.array<getitem, shape=(1830, 2044), dtype=float64, chunksize=(1830, 2044), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     channel   int64 dask.array<chunksize=(), meta=np.ndarray>\n",
       "   * col       (col) int64 0 1 2 3 4 5 6 7 ... 2037 2038 2039 2040 2041 2042 2043\n",
       "     cycle     int64 dask.array<chunksize=(), meta=np.ndarray>\n",
       "     marker    <U8 'LMN1b'\n",
       "     obj_step  int64 ...\n",
       "   * row       (row) int64 0 1 2 3 4 5 6 7 ... 1823 1824 1825 1826 1827 1828 1829,\n",
       " 'GFAP': <xarray.DataArray 'm1a' (row: 1830, col: 2044)>\n",
       " dask.array<getitem, shape=(1830, 2044), dtype=float64, chunksize=(1830, 2044), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     channel   int64 dask.array<chunksize=(), meta=np.ndarray>\n",
       "   * col       (col) int64 0 1 2 3 4 5 6 7 ... 2037 2038 2039 2040 2041 2042 2043\n",
       "     cycle     int64 dask.array<chunksize=(), meta=np.ndarray>\n",
       "     marker    <U8 'GFAP'\n",
       "     obj_step  int64 ...\n",
       "   * row       (row) int64 0 1 2 3 4 5 6 7 ... 1823 1824 1825 1826 1827 1828 1829,\n",
       " 'ELAVL2': <xarray.DataArray 'm1a' (row: 1830, col: 2044)>\n",
       " dask.array<getitem, shape=(1830, 2044), dtype=float64, chunksize=(1830, 2044), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     channel   int64 dask.array<chunksize=(), meta=np.ndarray>\n",
       "   * col       (col) int64 0 1 2 3 4 5 6 7 ... 2037 2038 2039 2040 2041 2042 2043\n",
       "     cycle     int64 dask.array<chunksize=(), meta=np.ndarray>\n",
       "     marker    <U8 'ELAVL2'\n",
       "     obj_step  int64 ...\n",
       "   * row       (row) int64 0 1 2 3 4 5 6 7 ... 1823 1824 1825 1826 1827 1828 1829,\n",
       " 'MBP': <xarray.DataArray 'm1a' (row: 1830, col: 2044)>\n",
       " dask.array<getitem, shape=(1830, 2044), dtype=float64, chunksize=(1830, 2044), chunktype=numpy.ndarray>\n",
       " Coordinates:\n",
       "     channel   int64 dask.array<chunksize=(), meta=np.ndarray>\n",
       "   * col       (col) int64 0 1 2 3 4 5 6 7 ... 2037 2038 2039 2040 2041 2042 2043\n",
       "     cycle     int64 dask.array<chunksize=(), meta=np.ndarray>\n",
       "     marker    <U8 'MBP'\n",
       "     obj_step  int64 ...\n",
       "   * row       (row) int64 0 1 2 3 4 5 6 7 ... 1823 1824 1825 1826 1827 1828 1829}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plane_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############  CPU PART #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMN1b\n",
      "GFAP\n",
      "ELAVL2\n",
      "MBP\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() == False:\n",
    "\n",
    "    def get_cluster(queue_name = 'pe2', log_dir=None):\n",
    "        \"\"\" Make dask cluster w/ workers = 2 cores, 32 G mem, and 1 hr wall time.\n",
    "\n",
    "            return cluster, client\n",
    "        \"\"\"\n",
    "\n",
    "        cluster = SLURMCluster(\n",
    "                    queue = queue_name, \n",
    "                    cores = 6 ,\n",
    "                    memory = '60G',\n",
    "                    walltime='1:00:00')\n",
    "                    #extra=[\"--lifetime\", \"55m\", \"--lifetime-stagger\", \"4m\"])\n",
    "        client = Client(cluster, timeout=\"50s\")\n",
    "\n",
    "        return cluster, client\n",
    "\n",
    "    cluster, client = get_cluster()\n",
    "\n",
    "    def scale_cluster(count): \n",
    "        cluster.scale(count)\n",
    "        return cluster.dashboard_link\n",
    "    scale_cluster(5)\n",
    "\n",
    "    #Way 3: Computing the same using dask compute without persisting Data\n",
    "    val = np.max(labels)\n",
    "    \n",
    "    \n",
    "    def get_pixels(lab,pl):\n",
    "        m = plane_dict[pl].values[labels == lab+1].mean()\n",
    "        return m\n",
    "    \n",
    "    mean_intensity_per_marker = {}\n",
    "    for plane in plane_dict.keys():\n",
    "        \n",
    "        print(plane)\n",
    "    \n",
    "        with parallel_backend('dask',scheduler_host=cluster.scheduler._address,wait_for_workers_timeout=20):\n",
    "            mean_int = Parallel(n_jobs=-1)(delayed(get_pixels)(lab, pl = plane) for lab in range(val))\n",
    "        mean_intensity_per_marker.update({plane:mean_int})\n",
    "    \n",
    "    #intensity_dict = {}\n",
    "    #intensity_dict.update({'m1a':results})\n",
    "    with open(snakemake.output[0], 'wb') as f:\n",
    "        pickle.dump(mean_intensity_per_marker, f)\n",
    "        \n",
    "    client.close()\n",
    "    cluster.close()\n",
    "        \n",
    "    \n",
    "else:\n",
    "    \n",
    "    def get_mean_intensity(pl):\n",
    "        result_ar = np.zeros(mx)\n",
    "        tr = torch.from_numpy(pl)\n",
    "        for r in range(mx):\n",
    "            result_ar[r] = (tr[lab == r+1]).float().mean()\n",
    "        return result_ar\n",
    "\n",
    "    lab = torch.from_numpy(labels.astype('int'))\n",
    "    mx = np.max(labels)\n",
    "    \n",
    "    mean_intensity_per_marker = {}\n",
    "    for plane in plane_dict.keys():\n",
    "        pl = plane_dict[plane].values\n",
    "        mean_int = get_mean_intensity(pl)\n",
    "        mean_intensity_per_marker.update({plane:mean_int})\n",
    "    \n",
    "    with open(snakemake.output[0], 'wb') as f:\n",
    "        pickle.dump(mean_intensity_per_marker, f)\n",
    "    \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/jsingh/.conda/envs/spatial/lib/python3.9/site-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import tmpfile\n"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import dask\n",
    "from pyseq import image_analysis as ia\n",
    "from dask.distributed import Client\n",
    "import torch\n",
    "import joblib\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import skimage\n",
    "import time\n",
    "import pickle\n",
    "from os.path import exists, join\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import parallel_backend\n",
    "from dask.distributed import progress\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "labels = skimage.io.imread(Path(snakemake.input[1]))\n",
    "image_path = Path(snakemake.input[0])\n",
    "im_name = image_path.stem\n",
    "image = xr.open_zarr(image_path).to_array()\n",
    "image = image.squeeze().drop_vars('variable').rename(im_name)\n",
    "\n",
    "marker_list = ['LMN1b','GFAP','ELAVL2','MBP','PVALB','IBA1','PDGFRA','MAP2','NFH']\n",
    "\n",
    "plane_dict = {}\n",
    "\n",
    "for mark in marker_list:\n",
    "    try:\n",
    "        plane_dict.update({mark: image.sel(marker = mark)})\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "if torch.cuda.is_available() == False:\n",
    "\n",
    "    def get_cluster(queue_name = 'pe2', log_dir=None):\n",
    "        \"\"\" Make dask cluster w/ workers = 2 cores, 32 G mem, and 1 hr wall time.\n",
    "\n",
    "            return cluster, client\n",
    "        \"\"\"\n",
    "\n",
    "        cluster = SLURMCluster(\n",
    "                    queue = queue_name, \n",
    "                    cores = 6 ,\n",
    "                    memory = '60G',\n",
    "                    walltime='1:00:00')\n",
    "                    \n",
    "        client = Client(cluster, timeout=\"50s\")\n",
    "\n",
    "        return cluster, client\n",
    "\n",
    "    cluster, client = get_cluster()\n",
    "\n",
    "    def scale_cluster(count): \n",
    "        cluster.scale(count)\n",
    "        return cluster.dashboard_link\n",
    "    scale_cluster(5)\n",
    "\n",
    "    \n",
    "    val = np.max(labels)\n",
    "    \n",
    "    \n",
    "    def get_pixels(lab,pl):\n",
    "        m = plane_dict[pl].values[labels == lab+1].mean()\n",
    "        return m\n",
    "    \n",
    "    mean_intensity_per_marker = {}\n",
    "    for plane in plane_dict.keys():\n",
    "    \n",
    "        with parallel_backend('dask',scheduler_host=cluster.scheduler._address,wait_for_workers_timeout=20):\n",
    "            mean_int = Parallel(n_jobs=-1)(delayed(get_pixels)(lab, pl = plane) for lab in range(val))\n",
    "        mean_intensity_per_marker.update({plane:mean_int})\n",
    "    \n",
    "\n",
    "    with open(Path(snakemake.output[0]), 'wb') as f:\n",
    "        pickle.dump(mean_intensity_per_marker, f)\n",
    "        \n",
    "    client.close()\n",
    "    cluster.close()\n",
    "        \n",
    "    \n",
    "else:\n",
    "    \n",
    "    def get_mean_intensity(pl):\n",
    "        result_ar = np.zeros(mx)\n",
    "        tr = torch.from_numpy(pl)\n",
    "        for r in range(mx):\n",
    "            result_ar[r] = (tr[lab == r+1]).float().mean()\n",
    "        return result_ar\n",
    "\n",
    "    lab = torch.from_numpy(labels.astype('int'))\n",
    "    mx = np.max(labels)\n",
    "    \n",
    "    mean_intensity_per_marker = {}\n",
    "    for plane in plane_dict.keys():\n",
    "        pl = plane_dict[plane].values\n",
    "        mean_int = get_mean_intensity(pl)\n",
    "        mean_intensity_per_marker.update({plane:mean_int})\n",
    "    \n",
    "    with open(Path(snakemake.output[0]), 'wb') as f:\n",
    "        pickle.dump(mean_intensity_per_marker, f)\n",
    "    \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[204.1565924369748,\n",
       " 219.2435027124774,\n",
       " 197.16119736842103,\n",
       " 233.68440799999993,\n",
       " 199.79664189189182,\n",
       " 194.20469999999986,\n",
       " 183.08972433460076,\n",
       " 358.44147388059764,\n",
       " 418.94018958333294,\n",
       " 212.90533221476502,\n",
       " 156.59556486486485,\n",
       " 365.7232986111111,\n",
       " 165.17839473684214,\n",
       " 178.10893412526994,\n",
       " 163.8208304347826,\n",
       " 159.77677124183006,\n",
       " 174.28523369565218,\n",
       " 171.08142982456144,\n",
       " 181.10694495412844,\n",
       " 192.6503812351543,\n",
       " 176.92490237226275,\n",
       " 182.31477560975608,\n",
       " 194.53574879227057,\n",
       " 328.61229999999983,\n",
       " 278.45205803571446,\n",
       " 194.80943018480494,\n",
       " 221.98814909638546,\n",
       " 199.89550384615387,\n",
       " 173.03966400000004,\n",
       " 167.5411196172249,\n",
       " 228.30494692005246,\n",
       " 181.7110406504065,\n",
       " 232.51638414634147,\n",
       " 175.5658253968254,\n",
       " 186.34737719298246,\n",
       " 185.1118387096774,\n",
       " 484.4968318584066,\n",
       " 187.3802853982301,\n",
       " 170.65271720116618,\n",
       " 183.47643689320375,\n",
       " 182.9458898809524,\n",
       " 214.60364705882353,\n",
       " 277.55134895833316,\n",
       " 170.77353632478636,\n",
       " 182.5046763485477,\n",
       " 198.67561320754717,\n",
       " 168.0955785791173,\n",
       " 184.14165252293574,\n",
       " 193.81074999999998,\n",
       " 186.0635452488687,\n",
       " 175.42015509259258,\n",
       " 274.6211834061136,\n",
       " 180.17021499999996,\n",
       " 134.2984691780822,\n",
       " 174.99644469026552,\n",
       " 184.1676487179487,\n",
       " 180.51671472392638,\n",
       " 167.64211872146123,\n",
       " 180.89841331269352,\n",
       " 181.02421982758617,\n",
       " 173.36696902654876,\n",
       " 219.79467279411784,\n",
       " 190.07312589928057,\n",
       " 172.1254791304348,\n",
       " 217.44117610062892,\n",
       " 182.15736730360936,\n",
       " 183.48626431297708,\n",
       " 199.9605987124464,\n",
       " 188.35245444444445,\n",
       " 175.59012953367875,\n",
       " 227.17842105263145,\n",
       " 186.0473831521739,\n",
       " 180.20445394736845,\n",
       " 331.92113003663013,\n",
       " 192.75989945652177,\n",
       " 175.54764327485387,\n",
       " 222.02675041736276,\n",
       " 172.5896709677419,\n",
       " 184.55453619047617,\n",
       " 188.22884883720923,\n",
       " 133.87168429003023,\n",
       " 179.4407609090909,\n",
       " 179.34329895104895,\n",
       " 135.1449259868421,\n",
       " 184.36539497716896,\n",
       " 172.48750892857146,\n",
       " 188.9947383177569,\n",
       " 186.45041414141411,\n",
       " 200.70451865671643,\n",
       " 192.07996301020407,\n",
       " 188.50880671296298,\n",
       " 183.47002650176685,\n",
       " 186.26919117647063,\n",
       " 191.69977165354322,\n",
       " 208.87283478260838,\n",
       " 134.57077300613497,\n",
       " 215.4291722972968,\n",
       " 146.62469642857153,\n",
       " 208.78185294117645,\n",
       " 183.56555078124995,\n",
       " 199.63363636363633,\n",
       " 215.73267000000024,\n",
       " 214.2499191176472,\n",
       " 196.57513662790709,\n",
       " 244.5186166666671,\n",
       " 188.29115527950358,\n",
       " 135.9321724137931,\n",
       " 134.7777666666667,\n",
       " 134.6641933962264,\n",
       " 134.68905720823798,\n",
       " 135.21010135135137,\n",
       " 135.26521615720523,\n",
       " 134.76751505016722,\n",
       " 132.14790463917527]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 13:57:55,627 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "2022-08-25 13:57:55,629 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "2022-08-25 13:57:55,629 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "2022-08-25 13:57:55,634 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n"
     ]
    }
   ],
   "source": [
    "mean_intensity_per_marker['ELAVL2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "spatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
