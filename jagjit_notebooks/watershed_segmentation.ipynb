{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Watershed Segmentation\n",
    "\n",
    "In order to create a cell by gene expression matrix from image-based transcriptomics data, RNA\n",
    "spots must be assigned to cells. One approach is to binarize images of stained cellular structures\n",
    "to define cell boundaries. A problem arises when there are contiguous or partially overlapping\n",
    "cells, as is often the case in tissue. These clumped cells are mislabeled as one cell by connected\n",
    "component labeling.\n",
    "\n",
    "Watershed segmentation can be used to divide connected objects like clumped cells by finding\n",
    "watershed lines that separate pixel intensity basins. The classic method for computing pixel\n",
    "intensity values from a binary image is applying a distance transform, which labels foreground\n",
    "pixels furthest from the background with the lowest values and pixels close to the background\n",
    "with higher values. The overall effect after watershed is to segment objects into convex shapes,\n",
    "which is generally a good approximation for a cell or nucleus. More details about the watershed\n",
    "algorithm can be found\n",
    "`here <https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_watershed.html>`_.\n",
    "\n",
    "Starfish allows users to implement watershed segmentation into their pipelines in two ways. The\n",
    "first is to use :py:class:`.WatershedSegment` to explicitly define a\n",
    "segmentation pipeline. The second is to use :py:class:`.Watershed`, a predefined watershed\n",
    "segmentation pipeline that uses watershed segmented nuclei as seeds to run\n",
    "watershed segmentation on cell stain images.\n",
    "\n",
    "The predefined watershed segmentation pipeline will not work for all data, so this tutorial\n",
    "will first show you how you can replicate the predefined watershed segmentation pipeline using the\n",
    "classes and methods provided in :py:mod:`.morphology`. Then this tutorial will cover how to run\n",
    "the predefined segmentation pipeline.\n",
    "\n",
    "Inputs for this tutorial are :py:class:`.ImageStack`\\s:\n",
    "\n",
    "* registered primary images to mimic a cell stain\n",
    "* registered nuclei images to seed the water segmentation of cells\n",
    "\n",
    "Output is a :py:class:`.BinaryMaskCollection`:\n",
    "\n",
    "* each binary mask in the collection is a labeled cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'register_translation' from 'skimage.feature' (/gpfs/commons/home/jsingh/.conda/envs/spatial/lib/python3.9/site-packages/skimage/feature/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshowit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstarfish\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ApplyTransform, LearnTransform, Filter\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstarfish\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Axes, Levels\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstarfish\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data, FieldOfView\n",
      "File \u001b[0;32m~/.conda/envs/spatial/lib/python3.9/site-packages/starfish/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# configuration management.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     config,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# image processing methods and objects.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     image,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# spot detection and manipulation.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     spots,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     is_release_tag \u001b[38;5;28;01mas\u001b[39;00m __is_release_tag__,\n\u001b[1;32m     11\u001b[0m     version \u001b[38;5;28;01mas\u001b[39;00m __version__\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# display images and spots\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/spatial/lib/python3.9/site-packages/starfish/image.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstarfish\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     ApplyTransform,\n\u001b[1;32m      3\u001b[0m     Filter,\n\u001b[1;32m      4\u001b[0m     LearnTransform,\n\u001b[1;32m      5\u001b[0m     Segment,\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/spatial/lib/python3.9/site-packages/starfish/core/image/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_registration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ApplyTransform\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_registration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearnTransform\n",
      "File \u001b[0;32m~/.conda/envs/spatial/lib/python3.9/site-packages/starfish/core/image/_registration/LearnTransform/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearnTransformAlgorithm\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranslation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translation\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# autodoc's automodule directive only captures the modules explicitly listed in __all__.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m      6\u001b[0m     implementation_name\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m implementation_name, implementation_cls \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m()\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(implementation_cls, \u001b[38;5;28mtype\u001b[39m)\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(implementation_cls, LearnTransformAlgorithm))\n\u001b[1;32m     10\u001b[0m ))\n",
      "File \u001b[0;32m~/.conda/envs/spatial/lib/python3.9/site-packages/starfish/core/image/_registration/LearnTransform/translation.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_translation\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_geometric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimilarityTransform\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstarfish\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_registration\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms_list\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformsList\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'register_translation' from 'skimage.feature' (/gpfs/commons/home/jsingh/.conda/envs/spatial/lib/python3.9/site-packages/skimage/feature/__init__.py)"
     ]
    }
   ],
   "source": [
    "# First we need to create our inputs by filtering and registering in situ sequencing (ISS) data.\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from showit import image\n",
    "from starfish.image import ApplyTransform, LearnTransform, Filter\n",
    "from starfish.types import Axes, Levels\n",
    "from starfish import data, FieldOfView\n",
    "\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 150\n",
    "\n",
    "experiment = data.ISS()\n",
    "fov = experiment.fov()\n",
    "\n",
    "imgs = fov.get_image(FieldOfView.PRIMARY_IMAGES) # primary images\n",
    "dots = fov.get_image(\"dots\") # reference round for image registration\n",
    "nuclei = fov.get_image(\"nuclei\") # nuclei`\n",
    "\n",
    "# filter raw data\n",
    "masking_radius = 15\n",
    "filt = Filter.WhiteTophat(masking_radius, is_volume=False)\n",
    "filt.run(imgs, in_place=True)\n",
    "filt.run(dots, in_place=True)\n",
    "filt.run(nuclei, in_place=True)\n",
    "\n",
    "# register primary images to reference round\n",
    "learn_translation = LearnTransform.Translation(reference_stack=dots, axes=Axes.ROUND, upsampling=1000)\n",
    "transforms_list = learn_translation.run(imgs.reduce({Axes.CH, Axes.ZPLANE}, func=\"max\"))\n",
    "warp = ApplyTransform.Warp()\n",
    "warp.run(imgs, transforms_list=transforms_list, in_place=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Custom Watershed Pipeline\n",
    "\n",
    "Starfish allows the user to build a custom watershed segmentation pipeline. This tutorial\n",
    "will demonstrate how construct a pipeline by replicating the algorithm behind starfish's\n",
    ":py:class:`.Watershed` segmentation.\n",
    "\n",
    "In order to use this algorithm, the :term:`primary images<Primary Images>` must have higher\n",
    "background intensity in intracellular regions than extracellular regions such that the\n",
    "intracellular regions can be labeled foreground by thresholding. This is not always the case\n",
    "since it is usually beneficial to tune the microscope parameters to minimize background and\n",
    "increase the SNR of spots in the acquired primary images. :term:`Auxiliary images<Auxiliary\n",
    "Images>` with cell stains would be ideal for this purpose and should be used instead if\n",
    "experimentally feasible.\n",
    "\n",
    ":term:`Auxiliary images <Auxiliary Images>` with nuclear stains (e.g. DAPI) are also required in\n",
    "this algorithm to seed watershed segmentation of the cells. While a distance transformation of\n",
    "the binarized cell stain images could also be used to seed watershed, nuclear stained images\n",
    "are almost always included in an experiment. The advantage of using nuclei is that it will\n",
    "result in a more accurate number of cells since it is not as prone to over-segmentation\n",
    "artifacts as using the distance transform and nuclear stains are usually more robust than\n",
    "cellular stains.\n",
    "\n",
    "There are a number of parameters that need to be tuned for optimal segmentation. Generally,\n",
    "the same parameters can be used across an experiment unless there is variation in microscope\n",
    "settings or tissue characteristics (e.g. autofluorescence).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import methods for transformations on or to morphological data\n",
    "from starfish.morphology import Binarize, Filter, Merge, Segment\n",
    "\n",
    "# set parameters\n",
    "dapi_thresh = .18  # global threshold value for nuclei images\n",
    "stain_thresh = .22  # global threshold value for primary images\n",
    "min_dist = 57  # minimum distance (pixels) between nuclei distance transformed peaks\n",
    "min_allowed_size = 10  # minimum size (in pixels) of nuclei\n",
    "max_allowed_size = 10000  # maximum size (in pixels) of nuclei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This segmentation is done on 2D images so :py:class:`.reduce` is used to maximum intensity project\n",
    "and scale the primary and nuclei image volumes. Displaying the projected and scaled images can\n",
    "be useful for choosing thresholds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = imgs.reduce({Axes.CH, Axes.ZPLANE}, func=\"max\")\n",
    "stain = mp.reduce(\n",
    "    {Axes.ROUND},\n",
    "    func=\"mean\",\n",
    "    level_method=Levels.SCALE_BY_IMAGE)\n",
    "\n",
    "nuclei_mp_scaled = nuclei.reduce(\n",
    "    {Axes.ROUND, Axes.CH, Axes.ZPLANE},\n",
    "    func=\"max\",\n",
    "    level_method=Levels.SCALE_BY_IMAGE)\n",
    "\n",
    "f = plt.figure(figsize=(12,5))\n",
    "ax1 = f.add_subplot(121)\n",
    "nuclei_numpy = nuclei_mp_scaled._squeezed_numpy(Axes.ROUND, Axes.CH, Axes.ZPLANE)\n",
    "image(nuclei_numpy, ax=ax1, size=20, bar=True)\n",
    "plt.title('Nuclei')\n",
    "\n",
    "ax2 = f.add_subplot(122)\n",
    "image(\n",
    "    stain._squeezed_numpy(Axes.ROUND, Axes.CH, Axes.ZPLANE),\n",
    "    ax=ax2, size=20, bar=True)\n",
    "plt.title('Stain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain the seeds to watershed segment cells, the nuclei are labeled first.\n",
    ":py:class:`.ThresholdBinarize` thresholds and :py:class:`.MinDistanceLabel` labels the\n",
    "binarized nuclei by using a distance transform followed by watershed. :py:class:`.AreaFilter`\n",
    "then filters nuclei by area. The ``min_dist`` parameter that limits how close two\n",
    "peaks in the distance transformed image can be is key to preventing over-segmentation of nuclei\n",
    "with non-circular morphology but may also incorrectly merge two nuclei in close proximity.\n",
    "\n",
    "The binarized and segmented nuclei can be viewed to determine whether parameters need to be\n",
    "adjusted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_nuclei = Binarize.ThresholdBinarize(dapi_thresh).run(nuclei_mp_scaled)\n",
    "labeled_masks = Filter.MinDistanceLabel(min_dist, 1).run(binarized_nuclei)\n",
    "watershed_markers = Filter.AreaFilter(min_area=min_allowed_size, max_area=max_allowed_size).run(labeled_masks)\n",
    "\n",
    "plt.subplot(121)\n",
    "image(\n",
    "    binarized_nuclei.uncropped_mask(0).squeeze(Axes.ZPLANE.value).values,\n",
    "    bar=False,\n",
    "    ax=plt.gca(),\n",
    ")\n",
    "plt.title('Nuclei Thresholded')\n",
    "\n",
    "plt.subplot(122)\n",
    "image(\n",
    "    watershed_markers.to_label_image().xarray.squeeze(Axes.ZPLANE.value).values,\n",
    "    size=20,\n",
    "    cmap=plt.cm.nipy_spectral,\n",
    "    ax=plt.gca(),\n",
    ")\n",
    "plt.title('Found: {} cells'.format(len(watershed_markers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell stain image (i.e. primary image) is binarized and then the union of the binary cell\n",
    "image and binary nuclei image is used to create a mask for watershed. This ensures that the\n",
    "nuclei markers that seed watershed segmentation of cells are all within cells and that no area\n",
    "outside of cells is labeled.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_stain = Binarize.ThresholdBinarize(stain_thresh).run(stain)\n",
    "markers_and_stain = Merge.SimpleMerge().run([thresholded_stain, watershed_markers])\n",
    "watershed_mask = Filter.Reduce(\n",
    "    \"logical_or\",\n",
    "    lambda shape: np.zeros(shape=shape, dtype=np.bool)\n",
    ").run(markers_and_stain)\n",
    "\n",
    "image(\n",
    "    watershed_mask.to_label_image().xarray.squeeze(Axes.ZPLANE.value).values,\n",
    "    bar=False,\n",
    "    ax=plt.gca(),\n",
    ")\n",
    "plt.title('Watershed Mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to run seeded watershed segmentation. The pixel values of the cell stain\n",
    "define the topology of the watershed basins. The basins are filled starting from seeds,\n",
    "which are the nuclei markers. And the boundaries of the basins are the watershed mask.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segment.WatershedSegment(connectivity=np.ones((1, 3, 3), dtype=np.bool))\n",
    "\n",
    "# masks is BinaryMaskCollection for downstream steps\n",
    "masks = segmenter.run(\n",
    "    stain,\n",
    "    watershed_markers,\n",
    "    watershed_mask,\n",
    ")\n",
    "\n",
    "# display result\n",
    "image(\n",
    "    masks.to_label_image().xarray.squeeze(Axes.ZPLANE.value).values,\n",
    "    size=20,\n",
    "    cmap=plt.cm.nipy_spectral,\n",
    "    ax=plt.gca(),\n",
    ")\n",
    "plt.title('Segmented Cells')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-defined Watershed Segmentation Pipeline\n",
    "\n",
    "Running :py:class:`.Watershed` from the :py:mod:`.image` module (not to be confused with\n",
    ":py:class:`.WatershedSegment` from the :py:mod:`.morphology` module) is a convenient method to\n",
    "apply the same segmentation algorithm that was built in the previous section of this tutorial.\n",
    "It hardcodes the ``min_allowed_size`` and ``max_allowed_size`` of the nuclei to 10\n",
    "pixels and 1,000 pixels, respectively, but accepts the other user-defined parameters as arguments.\n",
    "\n",
    "Here is an example of how to run :py:class:`.Watershed` on the same set of images as the\n",
    "previous section. The intermediate results are saved as attributes of the\n",
    ":py:class:`.Watershed` instance and can be displayed to assess performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starfish.image import Segment\n",
    "\n",
    "# set parameters\n",
    "dapi_thresh = .18  # global threshold value for nuclei images\n",
    "stain_thresh = .22  # global threshold value for primary images\n",
    "min_dist = 57  # minimum distance (pixels) between nuclei distance transformed peaks\n",
    "\n",
    "seg = Segment.Watershed(\n",
    "    nuclei_threshold=dapi_thresh,\n",
    "    input_threshold=stain_thresh,\n",
    "    min_distance=min_dist\n",
    ")\n",
    "\n",
    "# masks is BinaryMaskCollection for downstream steps\n",
    "masks = seg.run(imgs, nuclei)\n",
    "\n",
    "# display intermediate images and result\n",
    "seg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "spatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
